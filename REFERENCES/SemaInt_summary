Semantic Integration in Heterogenous Databases using Neural Networks

This paper discusses a method of schema matching that employs neural networks in order to learn to which subset of attributes of a database A can an attribute of the database B belong to and what their percentage of similarity is. The method is different from others in that it makes use of a learning-based approach rather than a rule-based one. This learning is performed based on meta-data of the tables instead of the actual data i.e. certain features of each column are extracted using a database specific parser and these features, represented as vectors with values in the range (0,1) are used as identifiers for that column. Here, the assumption that attributes that represent the same or similar real world data will have similarity in their context and structure has been made. For example, employee salaries from two different tables will have the same features, such as they will both be values higher than 0 and will have similar range and values. However, while another attribute gross receipts will also have numerical values higher than 0, its range and values would be quite different from those of salaries. In this manner, each column can be represented as a set of features. Training is done in the following manner: First, for the training database, features are extracted and each attribute is essentially converted into a vector of length N. Next, an unsupervised algorithm, in this case a self-organized map, is used to cluster attributes representing similar values within a database together. The number of clusters M is an input provided by the user. Cluster centers from each cluster are then used to train a single hidden layer neural network with M outputs neurons. For testing i.e. check which attributes of a database B are similar to which attributes of the training database A, attribute features from B are passed to the neural network. The output gives the similarity percentage of the attribute with each cluster. Number of clusters define how refined the similarity check is going to be. High number of clusters mean that a single cluster will contain less attributes and each attribute of the testing database will be matched to a lesser number of attributes as opposed to when the number of clusters are lower and number of attributes within each cluster is high.
Features are created specific to data type. For character type, these are: ratio of numerical characters to total characters, number of white spaces, average, variance and coefficient of variance of used length and total length of the field.
For numeric data field, features are: average, variance, coefficient of variance, granularity, units.

Lacking -- This paper does not take into consideration the semantic title of the attribute. It also does not consider cases where one table may have multiple attributes clubbed into one while the other may have those as separate fields. 

Possible improvement -- We will check which data types occur in a given column and if a set pattern is found (as in address), each data type will be split i.e. if a column is of type text -- (int, char) then the int and char parts will be separated. Since the method above does not take names into consideration anyway, what name is given to the split attribute does not matter. 
