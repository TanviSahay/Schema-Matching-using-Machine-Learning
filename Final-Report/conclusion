Schema matching is crucial for allowing data sharing or to maintain meaningful inter-operations between various systems. However, manual creation of schema matchings is a very labour intensive and tedious task and is prone to inclusion of human errors. At present, several research techniques have been proposed to decrease human involvement in one-to-one mapping and make most of them make use of machine learning methods to achieve their purpose. However, these methods require a lot of data to properly train the models as they either use pure supervised networks like naive bayes and logistic regression or a combination of unsupervised and supervised models. In this project, we have taken a different approach towards finding one-to-one schema matchings. Our methodology is based on a purely unsupervised mmodel of machine learning, which is to cluster similar attributes of a source table together and find linguistic mappings between source and test table attributes within each same cluster. A direct advantage of this method is that time required to find mappings between the two tables is reduced significantly, since rather than comparing every attribute of test table with that of train table, only attributes lying inside a particular cluster are taken as candidate matches. The method only has to bear a one-time cost of clustering similar attributes in the source table together. The first method i.e. centroid method performs worse than the combined method, with their respective scores of 0.60 and 0.75. While neither of the methods perform exceptionally well, taking into account the differences in the type and amount of data used, unbiased comparison with other methods is not possible. 

Both centroid and combined methods have different applications. It can be observed that in centroid method, since every test attribute is forced to map to atleast one train attribute so it can be used in scenarios where selective mapping is required. Lets consider a bank having many branches and one of its branch is shutting down, so its data is requied to be merged with the base branch. In this case, every field of branch which is shutting down should be matched with the base branch.
Now in combined method, since there are clusters of just train or test attributes i.e there are attributes for which no mapping is available so it can be used in scenarios where one company is acquiring other company and their databases needs to be merged. In this case, it can happen that one company has some field/information about its customers which other doesnt have and those fields should not be mapped.

-----rationalise edit distance for our database.
-----rationalise the cluster size.

-----experimentation - different cluster sizes - edit,cosine,eucledian, -precision,recall and F-score.



 Currently, vast variety of work has been done to decrease the human intervention in one-to-one mapping using machine learning techniques but that requires a large amount of data to train their models. Those approaches are using supervised methods of machine learning in which firstly a model needs to be trained using large amount of data and then it is tested with the test data. In this project, we have proposed a different approach for finding the one-to-one schema matching. Our methodology is based on the unsupervised methods of machine learning, which is to cluster the similar attributes together and then finding the linguistic mappings between train and test table attributes within the same cluster. Two techniques have been used to perform clustering and linguistic mapping namely centroid and combined. In first, only train attributes are clustered and then test table attributes are mapped to the cluster having minimum centroid distance. In second, both train and test table attributes are clustered together and then test table is mapped to train table within the same cluster. We have also proposed a solution to find one-to-many schema mappings using the global dictionary which is created manually by the domain expert before finding mappings across two tables.

We experimented our model on medical database and validated the mappings with precision and recall score. Both methods of one-to-one mappings achieve 60-68% accuracy. One important observation with this approach is that it can be used in the scenarios where very less amount of data is available. Also, the features are created in such a way that while clustering all the similar attributes will come together and the test attribute will only be compared to a set of train attributes having the similar feature. 
